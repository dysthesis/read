#!/usr/bin/env sh
set -eu

XDG_CACHE_HOME=${XDG_CACHE_HOME:-"$HOME/.local/share"}
XDG_CONFIG_HOME=${XDG_CONFIG_HOME:-"$HOME/.config"}
CACHE_DIR=${CACHE_DIR:-"$XDG_CACHE_HOME/read"}
CACHE_FILE="$CACHE_DIR/contents.json"
SCORE_CACHE_DIR="$CACHE_DIR/scores"

READ_FILE="$CACHE_DIR/read.txt"
SHOW_FLAG="$CACHE_DIR/show_read.flag" # its existence means "show all"

mkdir -p "$CACHE_DIR" "$SCORE_CACHE_DIR"
touch "$READ_FILE"

is_read() { grep -Fxq "$1" "$READ_FILE" 2>/dev/null; }
mark_read() { is_read "$1" || printf '%s\n' "$1" >>"$READ_FILE"; }
unmark_read() { [ -f "$READ_FILE" ] && grep -Fxv "$1" "$READ_FILE" >"$READ_FILE.$$" && mv "$READ_FILE.$$" "$READ_FILE"; }
toggle_show() { [ -e "$SHOW_FLAG" ] && rm -f "$SHOW_FLAG" || : >"$SHOW_FLAG"; }

export READ_FILE SHOW_FLAG

CLIP_CMD=${CLIP_CMD:-$(
  if command -v wl-copy >/dev/null 2>&1; then
    printf '%s' 'wl-copy'
  elif command -v xclip >/dev/null 2>&1; then
    printf '%s' 'xclip -selection clipboard'
  elif command -v pbcopy >/dev/null 2>&1; then
    printf '%s' 'pbcopy'
  else printf '%s' 'cat'; fi # fallback does nothing, but never crashes
)}
export CLIP_CMD

SHELL="sh"

LIKED_FILE="$CACHE_DIR/liked.txt"
DISLIKED_FILE="$CACHE_DIR/disliked.txt"
# CACHE: Ensure feedback files exist
touch "$LIKED_FILE" "$DISLIKED_FILE"

URLS=${URLS:-$XDG_CONFIG_HOME/read/feeds} # file containing feed URLs, one per line
JOBS=${JOBS:-64}                          # maximum concurrent feed workers

export CACHE_FILE LIKED_FILE DISLIKED_FILE

log() { printf '%s\n' "$*" >&2; }

GIT=$(command -v git || true)

init_git_repo() {
  [ -n "$GIT" ] || return
  if [ ! -d "$CACHE_DIR/.git" ]; then
    git -C "$CACHE_DIR" init -q # new repo
  fi
}

commit_if_changed() {
  [ -n "$GIT" ] || return
  # Take an exclusive lock to avoid concurrent writers
  exec 9>"$CACHE_DIR/.git/commit.lock" && flock -n 9 || return # silently skip if busy
  git -C "$CACHE_DIR" add -A
  if ! git -C "$CACHE_DIR" diff-index --quiet HEAD --; then # changes?
    git -C "$CACHE_DIR" commit -q -m "state: $(date -Iseconds)"
  fi
  flock -u 9 # release
}

init_git_repo

# emit $1 as a single-quoted shell string, POSIX portable
shell_quote() {
  printf "'%s'" "$(printf '%s' "$1" | sed "s/'/'\\\\''/g")"
}
update_feeds() {
  tmp=$(mktemp -d) || exit 1
  trap 'rm -rf "$tmp" "$sem"' EXIT INT HUP TERM

  sem=$(mktemp -u)
  mkfifo "$sem"
  exec 3<>"$sem" 4>&3
  rm "$sem" # remove pathname; FIFO stays open
  i=0
  while [ "$i" -lt "$JOBS" ]; do # preload N tokens
    printf '\n' >&4
    i=$((i + 1))
  done

  i=0
  while IFS= read -r feed || [ -n "$feed" ]; do
    IFS= read -r _ <&3 # wait for a free token
    i=$((i + 1))

    {
      log "[#${i}] Fetching $feed..."

      if ! data=$(curl -sL --retry 3 --max-time 20 "$feed"); then
        log "[#${i}] curl failed ($?) – feed ignored"
        printf '[]' >"$tmp/$i.json"
        printf '\n' >&4 # return token
        exit 0
      fi

      json=$(printf '%s' "$data" | r 2>"$tmp/r-${i}.err")
      r_status=$?
      if [ "$r_status" -ne 0 ]; then
        log "[#${i}] r exited $r_status – feed ignored"
        printf '[]' >"$tmp/$i.json"
        printf '\n' >&4
        exit 0
      fi

      printf '%s\n' "$json" |
        jq -c '.[]' | # stream objects, one per line
        while IFS= read -r art; do
          url=$(printf '%s\n' "$art" | jq -r '.url // empty')
          [ -z "$url" ] && {
            printf '%s\n' "$art"
            continue
          }

          mkdir -p "$tmp/bodies"
          tmp_body=$(mktemp "$tmp/bodies/body.XXXXXX") || {
            log "mktemp failed"
            continue
          }

          # 1.  Produce Markdown → file (with safety belt)
          if clean --markdown "$url" 2>>"$CACHE_DIR/clean.err" >"$tmp_body"; then
            # 2.  Merge without huge argv / without python
            printf '%s\n' "$art" |
              jq --rawfile body "$tmp_body" '.content = $body'
          else
            log "[#${i}] body skipped – clean failed for $url"
            printf '%s\n' "$art"
          fi

          rm -f -- "$tmp_body"
        done |
        jq -s '.' >"$tmp/$i.json" # re-assemble array

      printf '\n' >&4 # return token
    } &
  done <"$URLS"

  wait

  log '[+] Merging...'
  find "$tmp" -name '*.json' -print0 |
    xargs -0 cat | jq -s 'add' >"$CACHE_FILE"

  log "[+] Written merged array to $CACHE_FILE"
  commit_if_changed
}

compute_and_cache_score() {
  id=$1
  text=$2
  safe_id=$(printf '%s' "$id" | tr -c 'a-zA-Z0-9._-' '_')
  cache_path="$SCORE_CACHE_DIR/$safe_id"

  like=0
  dis=0

  tmp=$(mktemp -t read_score.XXXXXX) || {
    printf >&2 'mktemp failed\n'
    return 1
  }
  printf '%s' "$text" >"$tmp"

  if [ -s "$LIKED_FILE" ]; then
    like=$(sim "$tmp" "$LIKED_FILE" | awk '{print $NF+0}')
  fi
  if [ -s "$DISLIKED_FILE" ]; then
    dis=$(sim "$tmp" "$DISLIKED_FILE" | awk '{print $NF+0}')
  fi

  rm -f -- "$tmp"

  awk -v a="$like" -v b="$dis" 'BEGIN{printf "%.3f", a-b}' | tee "$cache_path"
}

build_menu() {
  if [ -z "${AUTHOR_CLR-}" ]; then
    colors=$(tput colors 2>/dev/null || printf %s 0)
    if [ "$colors" -ge 256 ]; then
      AUTHOR_CLR=$(tput setaf 244)
    elif [ "$colors" -ge 16 ]; then
      AUTHOR_CLR=$(tput setaf 8)
    else
      AUTHOR_CLR=$(tput dim)
    fi
    TITLE_CLR=$(tput bold)
    RESET=$(tput sgr0)
  fi

  read_vis=$([ -e "$SHOW_FLAG" ] && echo 1 || echo 0)
  idx=0

  {
    jq -r '.[] | [.id, .title, (if .author != null and .author != "" then .author else if .source_title != null and .source_title != "" then .source_title else "Unknown" end end), .content] | @tsv' "$CACHE_FILE" |
      awk -F'\t' \
        -v read_vis="$read_vis" \
        -v cache_dir="$SCORE_CACHE_DIR" \
        -v title_clr="$TITLE_CLR" \
        -v author_clr="$AUTHOR_CLR" \
        -v reset_clr="$RESET" \
        '
      # Block 1: Runs once. Loads read IDs into memory.
      BEGIN {
        while ((getline line < ARGV[1]) > 0) read_ids[line] = 1
        close(ARGV[1])
        ARGV[1] = ""
      }

      # Block 2: Runs for every article.
      {
        id = $1; title = $2; author = $3; content = $4

        # Filter out read articles if necessary
        if (read_vis == 0 && id in read_ids) next

        # Sanitize ID and build cache path INSIDE AWK
        safe_id = id
        gsub(/[^a-zA-Z0-9._-]/, "_", safe_id)
        cache_path = cache_dir "/" safe_id

        score = "UNCACHED" # Default score status
        # Try to read the score from the cache.
        # If getline succeeds, it returns 1 and sets `cached_score`.
        if ((getline cached_score < cache_path) > 0) {
          score = cached_score
          close(cache_path)
        }

        # If score is cached, print the fully formatted fzf line and continue.
        # This is the FAST PATH. No shell interaction needed.
        if (score != "UNCACHED") {
          printf "%s\t%s\t%s%s%s\t%s – %s%s\t%s%s%s\n",
            score, NR, title_clr, title, reset_clr,
            author_clr, author, reset_clr,
            author_clr, score, reset_clr
          next
        }

        # If we reach here, it is a CACHE MISS.
        # Print a special format for the shell to process.
        # We prefix with "SLOWPATH" to make it easy to filter.
        printf "SLOWPATH\t%s\t%s\t%s\t%s\t%s\n",
          id, title, author, content, NR
      }
    ' "$READ_FILE" # awk reads read.txt here
  } | {
    # This block processes the combined output. It receives fully-formatted lines (fast path) and
    # SLOWPATH lines.
    while IFS=$(printf '\t') read -r type col1 col2 col3 col4 col5; do
      if [ "$type" = "SLOWPATH" ]; then
        # A score needs to be computed
        id=$col1
        title=$col2
        author=$col3
        content=$col4
        line_num=$col5

        # Call the dedicated function to do the expensive work
        score=$(compute_and_cache_score "$id" "$content")

        # Now format the line, just like awk did for the fast path
        printf '%s\t%s\t%s%s%s\t%s – %s%s\t%s%s%s\n' \
          "$score" "$line_num" "${TITLE_CLR}" "${title}" "${RESET}" \
          "${AUTHOR_CLR}" " ${author}" "${RESET}" \
          "${AUTHOR_CLR}" "${score}" "${RESET}"
      else
        # The line is already perfectly formatted by awk. We just pass it through.
        printf '%s\t%s\t%s\t%s\t%s\n' "$type" "$col1" "$col2" "$col3" "$col5"
      fi
    done
  } | sort -r -n -k1,1
}

preview_cmd() {
  cat <<'EOS'
idx={2}
jq -r ".[$idx].content" "$CACHE_FILE" | mdcat
EOS
}

open_viewer() {
  idx=$1
  jq -r ".[$idx].content" "$CACHE_FILE" | mdcat -p --columns=100
}

open_and_mark() {
  idx=$1
  id=$(jq -r ".[$idx].id" "$CACHE_FILE")
  mark_read "$id"
  open_viewer "$idx"
}

append_feedback() {
  idx=$1 file=$2
  jq -r ".[$idx].content" "$CACHE_FILE" >>"$file"
  printf '\n' >>"$file"

  # The feedback files have changed, so all scores are now invalid.
  # Remove the cache directory so scores will be recalculated next time.
  log "Invalidating score cache..."
  rm -rf "$SCORE_CACHE_DIR"
  mkdir -p "$SCORE_CACHE_DIR"

  commit_if_changed
}

copy_url() { # copy_url <idx>
  idx=$1
  url=$(jq -r ".[$idx].url // empty" "$CACHE_FILE") || return
  [ -n "$url" ] || return # nothing to copy
  printf '%s' "$url" | eval "$CLIP_CMD" >/dev/null 2>&1
}

fzf_loop() {
  # CACHE: Pass SCORE_CACHE_DIR into the fzf environment
  export SCORE_CACHE_DIR
  build_menu |
    fzf --ansi \
      --multi \
      --no-sort \
      --header="read - feed reader" \
      --header-first \
      --prompt="Search: " \
      --layout=reverse \
      --delimiter='\t' \
      --with-nth=3.. \
      --preview "$(preview_cmd)" \
      --preview-window=right:60%:wrap \
      --bind "alt-l:execute-silent($(shell_quote "$0") __like {2})+reload($(shell_quote "$0") __menu)" \
      --bind "alt-d:execute-silent($(shell_quote "$0") __dislike {2})+reload($(shell_quote "$0") __menu)" \
      --bind "alt-y:execute-silent($(shell_quote "$0") __copy {2})" \
      --bind "enter:execute($(shell_quote "$0") __view {2})+reload($(shell_quote "$0") __menu)" \
      --bind "alt-u:execute-silent($(shell_quote "$0") __unread {2}) \
                +reload($(shell_quote "$0") __menu)" \
      --bind "alt-r:execute-silent($(shell_quote "$0") __toggle)+reload($(shell_quote "$0") __menu)"
}

case ${1:-show} in
update) update_feeds ;;
__view)
  shift
  open_and_mark "$1"
  ;;
__like)
  shift
  append_feedback "$1" "$LIKED_FILE"
  ;;
__dislike)
  shift
  append_feedback "$1" "$DISLIKED_FILE"
  ;;
__menu) build_menu ;;
__markread)
  shift
  id=$(jq -r ".[$1].id" "$CACHE_FILE")
  mark_read "$id"
  commit_if_changed
  ;;
__unread)
  shift
  id=$(jq -r ".[$1].id" "$CACHE_FILE")
  unmark_read "$id"
  commit_if_changed
  ;;
__toggle) toggle_show ;; # no commit; purely a view flag
__copy)
  shift
  copy_url "$1"
  ;;
show | *) fzf_loop ;;
esac
